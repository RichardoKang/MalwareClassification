import re
import numpy as np
from sklearn.feature_extraction import FeatureHasher

# 特征种类
class FeatureType:
    """ 每个特征类型都可以继承的基类。 """

    name = '' # 特征类型的名称
    dim = 0 # 特征类型的维度

    def __repr__(self):
        """ 返回特征类型的字符串表示。 """
        return '{}({})'.format(self.name, self.dim)

    def raw_features(self, bytez):
        """ 从样本中提取原始特征。 """
        raise NotImplementedError

    def process_raw_features(self, raw_obj):
        """ 对原始特征进行处理。 """
        raise NotImplementedError

    def feature_vector(self, bytez):
        """ 从样本中提取特征向量。 """
        return self.process_raw_features(self.raw_features(bytez))


# 字节直方图
class ByteHistogram(FeatureType):

    name = 'bytehist'
    dim = 256

    def __init__(self):
        """ 初始化一个字节直方图特征类型。 """
        super(FeatureType, self).__init__()

    def raw_features(self, bytez):
        """ 从样本中提取原始特征。 """
        counts = np.bincount(np.frombuffer(bytez, dtype=np.uint8), minlength=256)
        return counts.tolist()

    def process_raw_features(self, raw_obj):
        """ 对原始特征进行处理。 """
        counts = np.array(raw_obj, dtype=np.float32)
        sum = counts.sum()
        normalized = counts / sum
        return normalized


# 字节熵直方图
class ByteEntropyHistogram(FeatureType):

    name = 'byteentropyhist'
    dim = 256

    def __init__(self, step=1024, window=2048):
        """ 初始化一个字节熵直方图特征类型。 """
        super(FeatureType, self).__init__()
        self.step = step
        self.window = window

    # 从样本中提取原始特征
    def _entropy_bin_counts(self, block):
        # 粗直方图，每个bin 16个字节
        c = np.bincount(block >> 4, minlength=16)
        p = c.astype(np.float32) / self.window
        # 筛选非零的bin
        wh = np.where(c)[0]
        #  "* 2" b.c. 将信息减少了一半：256个bin（8位）减少到16个bin（4位）
        H = np.sum(-p[wh] * np.log2(p[wh])) * 2
        # 最多16个bin（最大熵为8位）
        Hbin = int(H * 2)
        # 处理熵=8.0位
        if Hbin == 16:
            Hbin = 15
        return Hbin, c

    # 从样本中提取原始特征
    def raw_features(self, bytez):
        output = np.zeros((16, 16), dtype=np.int)
        a = np.frombuffer(bytez, dtype=np.uint8)
        if a.shape[0] < self.window:
            Hbin, c = self._entropy_bin_counts(a)
            output[Hbin, :] += c
        else:
            # Strided trick
            shape = a.shape[:-1] + (a.shape[-1] - self.window + 1, self.window)
            strides = a.strides + (a.strides[-1],)
            blocks = np.lib.stride_tricks.as_strided(a, shape=shape, strides=strides)[::self.step, :]
            # From the blocks, compute histogram
            for block in blocks:
                Hbin, c = self._entropy_bin_counts(block)
                output[Hbin, :] += c
        return output.flatten().tolist()

    def process_raw_features(self, raw_obj):
        counts = np.array(raw_obj, dtype=np.float32)
        sum = counts.sum()
        # 归一化，指定axis=1，对每一行进行归一化
        normalized = counts / sum
        return normalized

# 字节提取(PE & asm files)
class StringExtractor(FeatureType):
    """ 从样本中提取字符串。"""
    name = 'strings'
    name_tfidf = 'words'
    dim = 1 + 1 + 1 + 96 + 1 + 1 + 1 + 1 + 1  # 104

    def __init__(self):
        super(FeatureType, self).__init__()
        # 所有连续的可打印字符串，长度大于5
        self._allstrings = re.compile(b'[\x20-\x7f]{5,}')
        # 字符串'C:\'的出现，实际上并没有提取路径
        self._paths = re.compile(b'c:\\\\', re.IGNORECASE)
        # 符串'http://'或'https://'的出现，实际上并没有提取URL
        self._urls = re.compile(b'https?://', re.IGNORECASE)
        # 字符串前缀'HKEY_'的出现，实际上并没有提取注册表名称
        self._registry = re.compile(b'HKEY_')
        # MZ头的粗略证据（PE滴管器或气泡式可执行文件）在字节流中的某个地方
        self._mz = re.compile(b'MZ')
        # 所有可以读的单词
        self._words = re.compile(b"[a-zA-Z]+")


    def tfidf_features(self, bytez):
        """ 从样本中提取TF-IDF特征。 """
        list_ = []
        list2 = []
        words = []
        for line in bytez:
            raw_words = re.findall('[a-zA-Z]+', line) # 提取所有可以读的单词
            words_space = ' '.join(w for w in raw_words if 4 < len(w) < 20) # 过滤掉长度小于4和大于20的单词
            list_.append(words_space) # 将单词加入列表
        for item in list_:  # 第2轮清洗，过滤掉小于3的字符串
            if len(item) > 3:
                list2.append(item)
        for item in list2:  # 第3轮清洗,对过长的字符串进行拆分
            if len(item) > 20:
                for text in item.split():
                    if (('a' in text) or ('e' in text) or ('i' in text) or ('o' in text) or ('u' in text) or (
                            'A' in text) or ('E' in text) or ('I' in text) or ('O' in text) or ('U' in text)):
                        if ('abcdef' not in text) and ('aaaaaa' not in text) and ('<init>' not in text):
                            words.append(text)

        return words

    def raw_features(self, bytez):
        allstrings = self._allstrings.findall(bytez) # 所有连续的可打印字符串，长度大于5
        if allstrings:
            # 关于字符串的统计
            string_lengths = [len(s) for s in allstrings] # 字符串长度
            avlength = sum(string_lengths) / len(string_lengths) # 字符串平均长度
            # 将可打印字符0x20 - 0x7f映射到一个整数数组，该数组由0-95组成，包括
            as_shifted_string = [b - ord(b'\x20') for b in b''.join(allstrings)]
            # 翻译成直方图计数
            c = np.bincount(as_shifted_string, minlength=96)
            # 可打印字符串中字符的分布（熵）
            csum = c.sum()
            p = c.astype(np.float32) / csum # 归一化
            wh = np.where(c)[0] # 筛选非零的bin
            H = np.sum(-p[wh] * np.log2(p[wh])) # 熵
        else:
            avlength = 0
            c = np.zeros((96,), dtype=np.float32) # 96个bin
            csum = 0
            H = 0
        return {
            'numstrings': len(allstrings), # 字符串数量
            'avlength': avlength, # 字符串平均长度
            'printabledist': c.tolist(), # 可打印字符的分布
            'printables': int(csum), # 可打印字符的数量
            'entropy': float(H), # 熵
            'paths': len(self._paths.findall(bytez)), # 路径数量
            'urls': len(self._urls.findall(bytez)), # URL数量
            'registry': len(self._registry.findall(bytez)), # 注册表数量
            'MZ': len(self._mz.findall(bytez)) # MZ数量
        }

    def process_raw_features(self, raw_obj):
        # 用于归一化的分母
        hist_divisor = float(raw_obj['printables']) if raw_obj['printables'] > 0 else 1.0
        # 返回特征向量
        return np.hstack([
            raw_obj['numstrings'], raw_obj['avlength'], raw_obj['printables'],
            np.asarray(raw_obj['printabledist']) / hist_divisor, raw_obj['entropy'], raw_obj['paths'], raw_obj['urls'],
            raw_obj['registry'], raw_obj['MZ']
        ]).astype(np.float32)
