import joblib
import numpy as np
import pandas as pd
import math
from utils import get_class_logloss
from sklearn.model_selection import StratifiedKFold, cross_val_score


class Model(object):
    """ 模型训练，交叉验证和预测。 """

    def __init__(self, model=None, X=None, y=None, label=None, inter_path=None, labels_loss = None):
        self.model = model # 模型
        self.X = X # 训练数据
        self.y = y # 训练标签
        self.label = label # 特征名
        self.inter_path = inter_path # 中间文件路径
        self.labels_loss = labels_loss # 类别损失

    def CrossValidation(self, n_splits):
        # 交叉验证
        cv = StratifiedKFold(n_splits=n_splits)
        cv_scores = cross_val_score(self.model, self.X, self.y, scoring='neg_log_loss', cv=cv)
        print(f"Logloss_mean after {n_splits} folds: {-np.mean(cv_scores):.6f}")

    def get_class_weight(self):
        # 计算每个类别在训练集上的logloss
        y_train = self.model.predict_proba(self.X)
        kclass_logloss = pd.DataFrame(y_train)
        kclass_logloss['family'] = self.y
        kclassloss = kclass_logloss.groupby('family').apply(get_class_logloss)

        self.labels_loss[self.label] = kclassloss
        self.labels_loss[np.isnan(self.labels_loss)] = 2  # logx 大于0 即可
        self.labels_loss = self.labels_loss.astype(float)
        self.labels_loss[self.label] = - self.labels_loss[self.label].apply(math.log)
        self.labels_loss[self.labels_loss < 0] = 0
        print(f"--------------------- {self.label}训练完成！ ---------------------")

        return self.labels_loss[self.label]

    def Fit(self):
        self.model.fit(self.X, self.y)
        joblib.dump(self.model, f"{self.inter_path}/models/XGB_model_{self.label}.pkl")

    def Predict(self, test_X):
        model = joblib.load(f"{self.inter_path}/models/XGB_model_{self.label}.pkl")
        test_y = model.predict_proba(test_X)
        return test_y
